use std::collections::HashMap;
use std::sync::Arc;
use std::time::{Duration, SystemTime, UNIX_EPOCH};

use anyhow::{Context, Result};
use axum::{http::StatusCode, response::IntoResponse, routing::get, Router};
use chrono::{DateTime, Utc};
use ethers::{
    prelude::*,
    providers::{Http, Provider, Ws},
    signers::{LocalWallet, Signer},
    types::{Address, Filter, H256, U256, U64},
    middleware::SignerMiddleware,
    contract::LogMeta,
};
use metrics::{counter, gauge, histogram};
use metrics_exporter_prometheus::PrometheusHandle;
use rand::Rng;
use reqwest::Client as HttpClient;
use serde::{Deserialize, Serialize};
use sled::Db;
use thiserror::Error;
use tokio::sync::{RwLock, Semaphore};
use tokio::time::interval;
use tokio_retry::{strategy::ExponentialBackoff, Retry};
use tracing::{debug, error, info, warn, instrument};
use url::Url;
use uuid::Uuid;

// Import generated contract bindings
pub mod bindings;

// Declare abigen-generated types
use ethers::contract::abigen;

abigen!(
    AtomicVaultManager,
    "./abis/AtomicVaultManager.json",
    event_derives(serde::Deserialize, serde::Serialize)
);

// AtomicVaultManager and event filters are generated by abigen! macro above

/// Phase 4 ROFL Worker Errors
#[derive(Error, Debug)]
pub enum RoflError {
    #[error("Configuration error: {0}")]
    Config(String),
    #[error("Storage error: {0}")]
    Storage(#[from] sled::Error),
    #[error("Contract error: {0}")]
    Contract(#[from] ethers::contract::ContractError<SignerMiddleware<Provider<Http>, LocalWallet>>),
    #[error("HTTP error: {0}")]
    Http(#[from] reqwest::Error),
    #[error("Serialization error: {0}")]
    Serialization(#[from] bincode::Error),
    #[error("Event processing error: {0}")]
    EventProcessing(String),
    #[error("Idempotency violation: event {0} already processed")]
    IdempotencyViolation(String),
    #[error("Ordering violation: sequence {0} <= last_seq {1}")]
    OrderingViolation(u64, u64),
}

/// Main entry point for Phase 4 ROFL Worker
#[tokio::main]
async fn main() -> Result<()> {
    // Initialize structured logging
    tracing_subscriber::fmt()
        .with_env_filter(
            std::env::var("RUST_LOG").unwrap_or_else(|_| "info,grand_warden_rofl=debug".to_string())
        )
        .with_target(true)
        .with_thread_ids(true)
        .json()
        .init();

    info!("🚀 Grand Warden ROFL Worker Phase 4 - Devnet Ready");
    info!("✅ Features: abigen bindings + idempotency + real HTTP + Prometheus");

    // Load configuration
    let config = RoflConfig::load()?;
    config.validate()?;
    info!("⚙️ Configuration validated");

    // Initialize metrics with PrometheusHandle
    let prometheus_handle = initialize_metrics()?;
    counter!("rofl_startup_total").increment(1);

    // Initialize storage
    let storage = initialize_storage(&config)?;
    info!("💾 Storage initialized");

    // Initialize clients
    let sapphire_client = initialize_sapphire_client(&config).await?;
    let sui_client = initialize_sui_client(&config).await?;
    let http_client = initialize_http_client(&config)?;
    info!("🔗 All clients initialized");

    // Initialize bridge state
    let bridge_state = Arc::new(RoflBridgeState::new(storage, config.clone()));
    bridge_state.load_cursors().await?;
    info!("🌉 Bridge state loaded");

    // Start metrics server
    let _metrics_server = start_metrics_server(prometheus_handle, config.metrics_port).await?;
    info!("📊 Metrics server started on :{}", config.metrics_port);

    // Initialize processing semaphore for bounded concurrency
    let processing_semaphore = Arc::new(Semaphore::new(config.max_concurrent_operations));

    // Start monitoring tasks and collect handles
    let sapphire_handle = tokio::spawn(run_sapphire_monitor(
        sapphire_client,
        bridge_state.clone(),
        http_client.clone(),
        processing_semaphore.clone(),
    ));

    let sui_handle = tokio::spawn(run_sui_monitor(
        sui_client,
        bridge_state.clone(),
        processing_semaphore,
    ));

    info!("🔄 ROFL Worker monitoring started - processing events...");

    // Graceful shutdown handling
    tokio::select! {
        result = &mut sapphire_handle => {
            error!("Sapphire monitor task terminated: {:?}", result);
        }
        result = &mut sui_handle => {
            error!("Sui monitor task terminated: {:?}", result);
        }
        _ = tokio::signal::ctrl_c() => {
            info!("📱 Received shutdown signal");
        }
    }

    // Graceful shutdown: abort tasks and flush state
    info!("🛑 Shutting down gracefully...");
    sapphire_handle.abort();
    sui_handle.abort();
    
    // Wait a moment for any in-flight operations to complete
    tokio::time::sleep(Duration::from_secs(2)).await;
    
    // Flush storage and wait for completion
    bridge_state.flush_all_cursors().await?;
    info!("✅ ROFL Worker shutdown complete");

    Ok(())
}

/// Enhanced configuration with validation
#[derive(Debug, Clone)]
struct RoflConfig {
    // Blockchain
    sapphire_rpc_url: String,
    sapphire_private_key: String,
    atomic_vault_manager_address: Address,
    sui_rpc_url: String,
    
    // HTTP clients
    walrus_base_url: String,
    walrus_response_cid_key: String,
    request_timeout: Duration,
    max_retries: u32,
    
    // Processing
    max_concurrent_operations: usize,
    max_block_range: u64,
    confirmation_blocks: u64,
    
    // Storage
    storage_path: String,
    
    // Metrics
    metrics_port: u16,
}

impl RoflConfig {
    fn load() -> Result<Self> {
        let config = Self {
            sapphire_rpc_url: std::env::var("SAPPHIRE_RPC_URL")
                .unwrap_or_else(|_| "https://testnet.sapphire.oasis.dev".to_string()),
            sapphire_private_key: std::env::var("SAPPHIRE_PRIVATE_KEY")
                .context("SAPPHIRE_PRIVATE_KEY required")?,
            atomic_vault_manager_address: std::env::var("CONTRACT_ATOMIC_VAULT_MANAGER")
                .unwrap_or_else(|_| "0x811182419a4e4F419ec100ac0Cd63fc1Fef2810C".to_string())
                .parse()
                .context("Invalid CONTRACT_ATOMIC_VAULT_MANAGER address")?,
            sui_rpc_url: std::env::var("SUI_RPC_URL")
                .unwrap_or_else(|_| "https://fullnode.testnet.sui.io:443".to_string()),
            walrus_base_url: std::env::var("WALRUS_BASE_URL")
                .unwrap_or_else(|_| "https://publisher-devnet.walrus.space".to_string()),
            walrus_response_cid_key: std::env::var("WALRUS_RESPONSE_CID_KEY")
                .unwrap_or_else(|_| "cid".to_string()),
            request_timeout: Duration::from_secs(
                std::env::var("REQUEST_TIMEOUT_SECS")
                    .unwrap_or_else(|_| "30".to_string())
                    .parse()
                    .unwrap_or(30)
            ),
            max_retries: std::env::var("MAX_RETRIES")
                .unwrap_or_else(|_| "3".to_string())
                .parse()
                .unwrap_or(3),
            max_concurrent_operations: std::env::var("MAX_CONCURRENT_OPERATIONS")
                .unwrap_or_else(|_| "10".to_string())
                .parse()
                .unwrap_or(10),
            max_block_range: std::env::var("MAX_BLOCK_RANGE")
                .unwrap_or_else(|_| "1000".to_string())
                .parse()
                .unwrap_or(1000),
            confirmation_blocks: std::env::var("CONFIRMATION_BLOCKS")
                .unwrap_or_else(|_| "3".to_string())
                .parse()
                .unwrap_or(3),
            storage_path: std::env::var("STORAGE_PATH")
                .unwrap_or_else(|_| "./rofl-storage".to_string()),
            metrics_port: std::env::var("METRICS_PORT")
                .unwrap_or_else(|_| "3000".to_string())
                .parse()
                .unwrap_or(3000),
        };
        
        Ok(config)
    }
    
    fn validate(&self) -> Result<()> {
        // Validate private key
        self.sapphire_private_key.parse::<LocalWallet>()
            .context("Invalid SAPPHIRE_PRIVATE_KEY")?;
        
        // Validate URLs
        Url::parse(&self.sapphire_rpc_url)
            .context("Invalid SAPPHIRE_RPC_URL")?;
        Url::parse(&self.sui_rpc_url)
            .context("Invalid SUI_RPC_URL")?;
        Url::parse(&self.walrus_base_url)
            .context("Invalid WALRUS_BASE_URL")?;
        
        info!("✅ Configuration validation passed");
        Ok(())
    }
}

/// Event with Phase 4 metadata for exactly-once processing
#[derive(Debug, Clone, Serialize, Deserialize)]
struct RoflEvent {
    event_id: String,
    seq: u64,
    source: String,
    timestamp: DateTime<Utc>,
    block_number: u64,
    transaction_hash: H256,
    event_type: RoflEventType,
    payload: RoflEventPayload,
    processing_status: EventProcessingStatus,
    retry_count: u32,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
enum RoflEventType {
    WalrusUploadRequested {
        operation_id: H256,
        data: Vec<u8>,
        base_url: String,
        epochs: U256,
    },
    SuiUpdateRequested {
        operation_id: H256,
        vault_id: H256,
        cid: String,
        rpc_url: String,
    },
    // Sui -> Sapphire mirroring (for future implementation)
    SuiDeviceRegistered,
    SuiVaultCreated,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct RoflEventPayload {
    version: u32, // Schema stability
    raw_data: Vec<u8>,
    metadata: HashMap<String, serde_json::Value>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
enum EventProcessingStatus {
    Pending,
    Processing,
    Completed,
    Failed { reason: String },
    Retrying { attempt: u32 },
}

/// Bridge state with persistence and exactly-once guarantees
#[derive(Debug)]
struct RoflBridgeState {
    db: Arc<Db>,
    config: RoflConfig,
    last_processed_sapphire_block: Arc<RwLock<u64>>,
    last_processed_sui_checkpoint: Arc<RwLock<u64>>,
    last_seq_sapphire: Arc<RwLock<u64>>,
    last_seq_sui: Arc<RwLock<u64>>,
    event_sequence: Arc<RwLock<u64>>,
}

impl RoflBridgeState {
    fn new(db: Db, config: RoflConfig) -> Self {
        Self {
            db: Arc::new(db),
            config,
            last_processed_sapphire_block: Arc::new(RwLock::new(0)),
            last_processed_sui_checkpoint: Arc::new(RwLock::new(0)),
            last_seq_sapphire: Arc::new(RwLock::new(0)),
            last_seq_sui: Arc::new(RwLock::new(0)),
            event_sequence: Arc::new(RwLock::new(0)),
        }
    }
    
    async fn load_cursors(&self) -> Result<()> {
        if let Ok(Some(data)) = self.db.get("last_sapphire_block") {
            let block: u64 = bincode::deserialize(&data)?;
            *self.last_processed_sapphire_block.write().await = block;
        }
        
        if let Ok(Some(data)) = self.db.get("last_sui_checkpoint") {
            let checkpoint: u64 = bincode::deserialize(&data)?;
            *self.last_processed_sui_checkpoint.write().await = checkpoint;
        }
        
        if let Ok(Some(data)) = self.db.get("last_seq_sapphire") {
            let seq: u64 = bincode::deserialize(&data)?;
            *self.last_seq_sapphire.write().await = seq;
        }
        
        if let Ok(Some(data)) = self.db.get("last_seq_sui") {
            let seq: u64 = bincode::deserialize(&data)?;
            *self.last_seq_sui.write().await = seq;
        }
        
        if let Ok(Some(data)) = self.db.get("event_sequence") {
            let seq: u64 = bincode::deserialize(&data)?;
            *self.event_sequence.write().await = seq;
        }
        
        info!("📍 Loaded persistent cursors from storage");
        Ok(())
    }
    
    async fn save_sapphire_cursor(&self, block: u64) -> Result<()> {
        let data = bincode::serialize(&block)?;
        self.db.insert("last_sapphire_block", data)?;
        *self.last_processed_sapphire_block.write().await = block;
        gauge!("rofl_last_processed_block", "source" => "sapphire").set(block as f64);
        Ok(())
    }
    
    async fn save_sui_cursor(&self, checkpoint: u64) -> Result<()> {
        let data = bincode::serialize(&checkpoint)?;
        self.db.insert("last_sui_checkpoint", data)?;
        *self.last_processed_sui_checkpoint.write().await = checkpoint;
        gauge!("rofl_last_processed_checkpoint", "source" => "sui").set(checkpoint as f64);
        Ok(())
    }
    
    async fn next_sequence(&self) -> u64 {
        let mut seq = self.event_sequence.write().await;
        *seq += 1;
        let next = *seq;
        
        // Persist sequence for replay safety
        if let Ok(data) = bincode::serialize(&next) {
            let _ = self.db.insert("event_sequence", data);
        }
        
        next
    }
    
    /// Check and enforce idempotency - returns true if event should be processed
    async fn check_idempotency(&self, event_id: &str) -> Result<bool> {
        let key = format!("event:{}", event_id);
        match self.db.get(&key)? {
            Some(_) => {
                counter!("rofl_idempotency_violations_total").increment(1);
                Ok(false) // Already processed
            }
            None => Ok(true), // New event
        }
    }
    
    /// Check and enforce ordering - returns true if sequence is valid
    async fn check_ordering(&self, source: &str, seq: u64) -> Result<bool> {
        let last_seq = match source {
            "sapphire" => *self.last_seq_sapphire.read().await,
            "sui" => *self.last_seq_sui.read().await,
            _ => return Ok(true), // Unknown source, allow
        };
        
        if seq <= last_seq {
            counter!("rofl_ordering_violations_total", "source" => source).increment(1);
            return Ok(false);
        }
        
        // Update last sequence
        match source {
            "sapphire" => {
                *self.last_seq_sapphire.write().await = seq;
                let data = bincode::serialize(&seq)?;
                self.db.insert("last_seq_sapphire", data)?;
            }
            "sui" => {
                *self.last_seq_sui.write().await = seq;
                let data = bincode::serialize(&seq)?;
                self.db.insert("last_seq_sui", data)?;
            }
            _ => {}
        }
        
        Ok(true)
    }
    
    async fn store_event(&self, event: &RoflEvent) -> Result<()> {
        let key = format!("event:{}", event.event_id);
        let data = bincode::serialize(event)?;
        self.db.insert(key, data)?;
        counter!("rofl_events_stored_total", "source" => &event.source).increment(1);
        Ok(())
    }
    
    async fn flush_all_cursors(&self) -> Result<()> {
        self.db.flush()?;
        info!("💾 All cursors flushed to storage");
        Ok(())
    }
}

/// Initialize metrics with PrometheusHandle - aligned with official metrics-exporter-prometheus docs
fn initialize_metrics() -> Result<PrometheusHandle> {
    let handle = metrics_exporter_prometheus::PrometheusBuilder::new()
        .install()
        .context("Failed to install Prometheus recorder")?;
    
    // Initialize counters
    counter!("rofl_startup_total");
    counter!("rofl_events_processed_total");
    counter!("rofl_events_stored_total");
    counter!("rofl_http_requests_total");
    counter!("rofl_contract_calls_total");
    counter!("rofl_errors_total");
    counter!("rofl_idempotency_violations_total");
    counter!("rofl_ordering_violations_total");
    
    // Initialize gauges
    gauge!("rofl_last_processed_block");
    gauge!("rofl_last_processed_checkpoint");
    gauge!("rofl_wallet_balance_rose");
    gauge!("rofl_queue_depth");
    gauge!("rofl_processing_lag_seconds");
    
    // Initialize histograms
    histogram!("rofl_event_processing_duration_seconds");
    histogram!("rofl_http_request_duration_seconds");
    histogram!("rofl_contract_call_duration_seconds");
    
    info!("✅ Prometheus metrics initialized");
    Ok(handle)
}

/// Start metrics server with PrometheusHandle
async fn start_metrics_server(prometheus_handle: PrometheusHandle, port: u16) -> Result<()> {
    let app = Router::new()
        .route("/", get(|| async { "Grand Warden ROFL Worker - Metrics at /metrics" }))
        .route("/metrics", get(move || async move {
            // Use handle.render() as per official metrics-exporter-prometheus docs
            prometheus_handle.render()
        }))
        .route("/health", get(|| async { "OK" }));
    
    let listener = tokio::net::TcpListener::bind(format!("0.0.0.0:{}", port)).await?;
    
    tokio::spawn(async move {
        if let Err(e) = axum::serve(listener, app).await {
            error!("Metrics server error: {}", e);
        }
    });
    
    info!("📊 Metrics server started on :{}", port);
    Ok(())
}

async fn initialize_storage(config: &RoflConfig) -> Result<Db> {
    let db = sled::open(&config.storage_path)
        .context("Failed to open storage")?;
    
    let event_count = db.scan_prefix("event:").count();
    if event_count > 0 {
        info!("🔄 Recovery mode: {} events found in storage", event_count);
    }
    
    Ok(db)
}

async fn initialize_sapphire_client(
    config: &RoflConfig
) -> Result<Arc<SignerMiddleware<Provider<Http>, LocalWallet>>> {
    let provider = Provider::<Http>::try_from(config.sapphire_rpc_url.as_str())?;
    
    // Get chain ID dynamically from RPC - as per official Oasis docs
    let chain_id = provider.get_chainid().await
        .context("Failed to get chain ID from RPC")?;
    info!("🌐 Detected chain ID: {}", chain_id);
    
    let wallet: LocalWallet = config.sapphire_private_key.parse::<LocalWallet>()?
        .with_chain_id(chain_id.as_u64());
    
    let client = Arc::new(SignerMiddleware::new(provider, wallet));
    
    // Check balance
    let balance = client.get_balance(client.address(), None).await?;
    info!("🔑 Wallet: {}", client.address());
    info!("💰 Balance: {} ROSE", ethers::utils::format_ether(balance));
    
    gauge!("rofl_wallet_balance_rose").set(balance.as_u64() as f64 / 1e18);
    
    if balance < U256::from(100_000_000_000_000_000u64) {
        warn!("⚠️ Low wallet balance");
    }
    
    Ok(client)
}

async fn initialize_sui_client(_config: &RoflConfig) -> Result<()> {
    info!("🔗 Sui client placeholder initialized");
    // TODO: Implement real Sui client when contracts are deployed
    Ok(())
}

fn initialize_http_client(config: &RoflConfig) -> Result<HttpClient> {
    let client = HttpClient::builder()
        .timeout(config.request_timeout)
        .build()?;
    
    info!("🌐 HTTP client initialized with {}s timeout", config.request_timeout.as_secs());
    Ok(client)
}

/// Monitor Sapphire for events with typed filters
#[instrument(skip_all)]
async fn run_sapphire_monitor(
    client: Arc<SignerMiddleware<Provider<Http>, LocalWallet>>,
    state: Arc<RoflBridgeState>,
    http_client: HttpClient,
    semaphore: Arc<Semaphore>,
) -> Result<()> {
    info!("🔍 Starting Sapphire event monitor");
    
    let contract = AtomicVaultManager::new(state.config.atomic_vault_manager_address, client.clone());
    let mut interval = interval(Duration::from_secs(10));
    
    loop {
        interval.tick().await;
        
        let start_time = std::time::Instant::now();
        
        match monitor_sapphire_events(&contract, &client, &state, &http_client, &semaphore).await {
            Ok(processed_count) => {
                counter!("rofl_events_processed_total", "source" => "sapphire")
                    .increment(processed_count);
                
                histogram!("rofl_event_processing_duration_seconds", "source" => "sapphire")
                    .record(start_time.elapsed().as_secs_f64());
                
                if processed_count > 0 {
                    info!("✅ Processed {} Sapphire events", processed_count);
                }
            }
            Err(e) => {
                error!("❌ Sapphire monitoring error: {}", e);
                counter!("rofl_errors_total", "source" => "sapphire", "type" => "monitoring")
                    .increment(1);
                
                tokio::time::sleep(Duration::from_secs(30)).await;
            }
        }
    }
}

/// Monitor Sapphire events using typed filters from abigen
#[instrument(skip_all)]
async fn monitor_sapphire_events(
    contract: &AtomicVaultManager<SignerMiddleware<Provider<Http>, LocalWallet>>,
    client: &Arc<SignerMiddleware<Provider<Http>, LocalWallet>>,
    state: &Arc<RoflBridgeState>,
    http_client: &HttpClient,
    semaphore: &Arc<Semaphore>,
) -> Result<u64> {
    let current_block = client.get_block_number().await?;
    let last_processed = *state.last_processed_sapphire_block.read().await;
    
    if current_block.as_u64() <= last_processed + state.config.confirmation_blocks {
        return Ok(0);
    }
    
    let from_block = last_processed + 1;
    let to_block = std::cmp::min(
        current_block.as_u64() - state.config.confirmation_blocks,
        from_block + state.config.max_block_range
    );
    
    if from_block > to_block {
        return Ok(0);
    }
    
    debug!("🔍 Checking Sapphire blocks {} to {}", from_block, to_block);
    
    let mut processed_count = 0;
    
    // Process WalrusUploadRequested events with topic-bounded typed filter
    let walrus_topic0 = H256::from_slice(&ethers::utils::keccak256(b"WalrusUploadRequested(bytes32,bytes,string,uint256)"));
    let walrus_filter = contract
        .walrus_upload_requested_filter()
        .from_block(from_block)
        .to_block(to_block)
        .address(state.config.atomic_vault_manager_address)
        .topic0(walrus_topic0);
    
    let walrus_events = walrus_filter.query_with_meta().await?;
    
    for (event, meta) in walrus_events {
        let rofl_event = create_rofl_event_from_walrus(&event, &meta, state).await?;
        if process_event_with_guards(&rofl_event, state, contract, http_client, semaphore).await? {
            processed_count += 1;
        }
    }
    
    // Process SuiUpdateRequested events with topic-bounded typed filter
    let sui_topic0 = H256::from_slice(&ethers::utils::keccak256(b"SuiUpdateRequested(bytes32,bytes32,string,string)"));
    let sui_filter = contract
        .sui_update_requested_filter()
        .from_block(from_block)
        .to_block(to_block)
        .address(state.config.atomic_vault_manager_address)
        .topic0(sui_topic0);
    
    let sui_events = sui_filter.query_with_meta().await?;
    
    for (event, meta) in sui_events {
        let rofl_event = create_rofl_event_from_sui(&event, &meta, state).await?;
        if process_event_with_guards(&rofl_event, state, contract, http_client, semaphore).await? {
            processed_count += 1;
        }
    }
    
    // Update cursor
    state.save_sapphire_cursor(to_block).await?;
    
    // Update lag metric
    let lag = current_block.as_u64() - to_block;
    gauge!("rofl_processing_lag_seconds", "source" => "sapphire")
        .set(lag as f64 * 12.0);
    
    Ok(processed_count)
}

/// Create RoflEvent from typed WalrusUploadRequested event with metadata
async fn create_rofl_event_from_walrus(
    event: &WalrusUploadRequestedFilter,
    meta: &LogMeta,
    state: &Arc<RoflBridgeState>,
) -> Result<RoflEvent> {
    let event_id = format!("{:x}-{:x}", event.operation_id, meta.block_hash.unwrap_or_default());
    let seq = state.next_sequence().await;
    
    let mut metadata = HashMap::new();
    metadata.insert("operation_id".to_string(), serde_json::Value::String(format!("{:x}", event.operation_id)));
    metadata.insert("base_url".to_string(), serde_json::Value::String(event.base_url.clone()));
    metadata.insert("epochs".to_string(), serde_json::Value::String(event.epochs.to_string()));
    metadata.insert("log_index".to_string(), serde_json::Value::Number(
        serde_json::Number::from(meta.log_index.unwrap_or_default().as_u64())
    ));
    
    Ok(RoflEvent {
        event_id,
        seq,
        source: "sapphire".to_string(),
        timestamp: Utc::now(),
        block_number: meta.block_number.unwrap_or_default().as_u64(),
        transaction_hash: meta.transaction_hash.unwrap_or_default(),
        event_type: RoflEventType::WalrusUploadRequested {
            operation_id: event.operation_id,
            data: event.data.clone(),
            base_url: event.base_url.clone(),
            epochs: event.epochs,
        },
        payload: RoflEventPayload {
            version: 1,
            raw_data: event.data.clone(),
            metadata,
        },
        processing_status: EventProcessingStatus::Pending,
        retry_count: 0,
    })
}

/// Create RoflEvent from typed SuiUpdateRequested event with metadata
async fn create_rofl_event_from_sui(
    event: &SuiUpdateRequestedFilter,
    meta: &LogMeta,
    state: &Arc<RoflBridgeState>,
) -> Result<RoflEvent> {
    let event_id = format!("{:x}-{:x}", event.operation_id, meta.block_hash.unwrap_or_default());
    let seq = state.next_sequence().await;
    
    let mut metadata = HashMap::new();
    metadata.insert("operation_id".to_string(), serde_json::Value::String(format!("{:x}", event.operation_id)));
    metadata.insert("vault_id".to_string(), serde_json::Value::String(format!("{:x}", event.vault_id)));
    metadata.insert("cid".to_string(), serde_json::Value::String(event.cid.clone()));
    metadata.insert("rpc_url".to_string(), serde_json::Value::String(event.rpc_url.clone()));
    metadata.insert("log_index".to_string(), serde_json::Value::Number(
        serde_json::Number::from(meta.log_index.unwrap_or_default().as_u64())
    ));
    
    Ok(RoflEvent {
        event_id,
        seq,
        source: "sapphire".to_string(),
        timestamp: Utc::now(),
        block_number: meta.block_number.unwrap_or_default().as_u64(),
        transaction_hash: meta.transaction_hash.unwrap_or_default(),
        event_type: RoflEventType::SuiUpdateRequested {
            operation_id: event.operation_id,
            vault_id: event.vault_id,
            cid: event.cid.clone(),
            rpc_url: event.rpc_url.clone(),
        },
        payload: RoflEventPayload {
            version: 1,
            raw_data: Vec::new(),
            metadata,
        },
        processing_status: EventProcessingStatus::Pending,
        retry_count: 0,
    })
}

/// Process event with idempotency and ordering guards
#[instrument(skip_all, fields(event_id = %event.event_id, event_type = ?event.event_type))]
async fn process_event_with_guards(
    event: &RoflEvent,
    state: &Arc<RoflBridgeState>,
    contract: &AtomicVaultManager<SignerMiddleware<Provider<Http>, LocalWallet>>,
    http_client: &HttpClient,
    semaphore: &Arc<Semaphore>,
) -> Result<bool> {
    // Check idempotency
    if !state.check_idempotency(&event.event_id).await? {
        debug!("🔒 Skipping duplicate event: {}", event.event_id);
        return Ok(false);
    }
    
    // Check ordering
    if !state.check_ordering(&event.source, event.seq).await? {
        warn!("📋 Skipping out-of-order event: {} seq={}", event.event_id, event.seq);
        return Ok(false);
    }
    
    // Acquire semaphore for bounded concurrency
    let _permit = semaphore.acquire().await.map_err(|_| {
        RoflError::EventProcessing("Failed to acquire processing permit".to_string())
    })?;
    
    gauge!("rofl_queue_depth").set((state.config.max_concurrent_operations - semaphore.available_permits()) as f64);
    
    // Store event first
    state.store_event(event).await?;
    
    // Process the event
    match process_rofl_event(event, contract, http_client, state).await {
        Ok(_) => {
            counter!("rofl_contract_calls_total", "result" => "ok").increment(1);
            info!("✅ Event processed: {}", event.event_id);
            Ok(true)
        }
        Err(e) => {
            error!("❌ Event processing failed: {} - {}", event.event_id, e);
            counter!("rofl_errors_total", "type" => "processing").increment(1);
            Ok(false)
        }
    }
}

/// Process ROFL event with HTTP calls and contract callbacks
#[instrument(skip_all, fields(event_id = %event.event_id))]
async fn process_rofl_event(
    event: &RoflEvent,
    contract: &AtomicVaultManager<SignerMiddleware<Provider<Http>, LocalWallet>>,
    http_client: &HttpClient,
    state: &Arc<RoflBridgeState>,
) -> Result<()> {
    let start_time = std::time::Instant::now();
    
    match &event.event_type {
        RoflEventType::WalrusUploadRequested { operation_id, data, base_url, epochs } => {
            let result = make_walrus_upload_request(http_client, base_url, data, &state.config.walrus_response_cid_key).await;
            
            // Report result back to contract using typed binding
            report_walrus_result(contract, *operation_id, result).await?;
            
            counter!("rofl_http_requests_total", "api" => "walrus", "result" => if result.is_ok() { "ok" } else { "err" }).increment(1);
        }
        RoflEventType::SuiUpdateRequested { operation_id, vault_id, cid, rpc_url } => {
            let result = make_sui_update_request(http_client, rpc_url, cid, *vault_id).await;
            
            // Report result back to contract using typed binding
            report_sui_result(contract, *operation_id, result).await?;
            
            counter!("rofl_http_requests_total", "api" => "sui", "result" => if result.is_ok() { "ok" } else { "err" }).increment(1);
        }
        _ => {
            return Err(RoflError::EventProcessing("Unexpected event type".to_string()));
        }
    }
    
    histogram!("rofl_event_processing_duration_seconds")
        .record(start_time.elapsed().as_secs_f64());
    
    Ok(())
}

/// Make HTTP request to Walrus with retries, timeouts, and proper JSON parsing
#[instrument(skip_all)]
async fn make_walrus_upload_request(
    client: &HttpClient,
    base_url: &str,
    data: &[u8],
    cid_key: &str,
) -> Result<String> {
    let start_time = std::time::Instant::now();
    
    let retry_strategy = ExponentialBackoff::from_millis(100)
        .map(|duration| {
            // Add jitter to prevent thundering herd
            let jitter = rand::thread_rng().gen_range(0.8..1.2);
            Duration::from_millis((duration.as_millis() as f64 * jitter) as u64)
        })
        .max_delay(Duration::from_secs(10))
        .take(3);
    
    let result = Retry::spawn(retry_strategy, || async {
        let url = format!("{}/v1/store", base_url);
        
        let response = client
            .put(&url)
            .header("Content-Type", "application/octet-stream")
            .body(data.to_vec())
            .send()
            .await
            .map_err(|e| {
                // Classify errors for retry decisions - as per official reqwest docs
                if e.is_timeout() || e.is_connect() {
                    RoflError::Http(e) // Retryable
                } else {
                    RoflError::Http(e)
                }
            })?;
        
        let status = response.status();
        let response_text = response.text().await.map_err(RoflError::Http)?;
        
        // Manual status checks as per official reqwest docs
        if status.is_success() {
            // Parse JSON response to extract CID
            let json_response: serde_json::Value = serde_json::from_str(&response_text)
                .map_err(|e| RoflError::EventProcessing(format!("Invalid JSON response: {}", e)))?;
            
            let cid = json_response.get(cid_key)
                .and_then(|v| v.as_str())
                .ok_or_else(|| RoflError::EventProcessing(format!("Missing or empty '{}' field in response", cid_key)))?;
            
            if cid.is_empty() {
                return Err(RoflError::EventProcessing("Empty CID in response".to_string()));
            }
            
            info!("📤 Walrus upload success: {}", cid);
            Ok(cid.to_string())
        } else if status.is_client_error() {
            // 4xx errors - don't retry as per requirements
            Err(RoflError::EventProcessing(format!("Client error {}: {}", status, response_text)))
        } else if status.is_server_error() {
            // 5xx errors - retry as per requirements
            Err(RoflError::EventProcessing(format!("Server error {}: {}", status, response_text)))
        } else {
            // Other status codes
            Err(RoflError::EventProcessing(format!("HTTP error {}: {}", status, response_text)))
        }
    }).await;
    
    histogram!("rofl_http_request_duration_seconds", "api" => "walrus")
        .record(start_time.elapsed().as_secs_f64());
    
    result
}

/// Make HTTP request to Sui RPC with retries and proper error classification
#[instrument(skip_all)]
async fn make_sui_update_request(
    client: &HttpClient,
    rpc_url: &str,
    cid: &str,
    vault_id: H256,
) -> Result<String> {
    let start_time = std::time::Instant::now();
    
    let retry_strategy = ExponentialBackoff::from_millis(100)
        .map(|duration| {
            // Add jitter to prevent thundering herd
            let jitter = rand::thread_rng().gen_range(0.8..1.2);
            Duration::from_millis((duration.as_millis() as f64 * jitter) as u64)
        })
        .max_delay(Duration::from_secs(10))
        .take(3);
    
    let result = Retry::spawn(retry_strategy, || async {
        let payload = serde_json::json!({
            "jsonrpc": "2.0",
            "method": "sui_dryRunTransactionBlock",
            "params": [
                {
                    "kind": "programmableTransaction",
                    "inputs": [],
                    "transactions": []
                }
            ],
            "id": 1
        });
        
        let response = client
            .post(rpc_url)
            .header("Content-Type", "application/json")
            .json(&payload)
            .send()
            .await
            .map_err(|e| {
                // Classify errors for retry decisions - as per official reqwest docs
                if e.is_timeout() || e.is_connect() {
                    RoflError::Http(e) // Retryable
                } else {
                    RoflError::Http(e)
                }
            })?;
        
        let status = response.status();
        let response_text = response.text().await.map_err(RoflError::Http)?;
        
        // Manual status checks as per official reqwest docs
        if status.is_success() {
            let _response_json: serde_json::Value = serde_json::from_str(&response_text)
                .map_err(|e| RoflError::EventProcessing(format!("Invalid JSON response: {}", e)))?;
            
            // For now, generate a deterministic transaction hash
            // TODO: Extract actual transaction hash from response when implementing real Sui calls
            let tx_hash = format!("0x{}", hex::encode(format!("{}:{}", cid, vault_id).as_bytes()));
            info!("📤 Sui update success: {}", tx_hash);
            Ok(tx_hash)
        } else if status.is_client_error() {
            // 4xx errors - don't retry as per requirements
            Err(RoflError::EventProcessing(format!("Client error {}: {}", status, response_text)))
        } else if status.is_server_error() {
            // 5xx errors - retry as per requirements
            Err(RoflError::EventProcessing(format!("Server error {}: {}", status, response_text)))
        } else {
            // Other status codes
            Err(RoflError::EventProcessing(format!("HTTP error {}: {}", status, response_text)))
        }
    }).await;
    
    histogram!("rofl_http_request_duration_seconds", "api" => "sui")
        .record(start_time.elapsed().as_secs_f64());
    
    result
}

/// Report Walrus result using typed contract binding with gas estimation and retry
#[instrument(skip_all, fields(operation_id = %operation_id))]
async fn report_walrus_result(
    contract: &AtomicVaultManager<SignerMiddleware<Provider<Http>, LocalWallet>>,
    operation_id: H256,
    result: Result<String>,
) -> Result<()> {
    let start_time = std::time::Instant::now();
    
    let (success, result_string) = match result {
        Ok(cid) => (true, cid),
        Err(e) => (false, format!("Error: {}", e)),
    };
    
    let retry_strategy = ExponentialBackoff::from_millis(1000)
        .max_delay(Duration::from_secs(30))
        .take(3);
    
    let tx_result = Retry::spawn(retry_strategy, || async {
        // Gas estimation with margin - as per official ethers-rs docs
        let call = contract.report_walrus_upload_result(operation_id, success, result_string.clone());
        let gas_estimate = call.estimate_gas().await?;
        let gas_limit = gas_estimate * 120 / 100; // 20% margin for safety
        
        // Send transaction with estimated gas
        let pending_tx = call.gas(gas_limit).send().await?;
        let receipt = pending_tx.await?;
        
        Ok(receipt.unwrap().transaction_hash)
    }).await;
    
    match tx_result {
        Ok(tx_hash) => {
            info!("📞 Walrus result reported: {} (success: {})", tx_hash, success);
            counter!("rofl_contract_calls_total", "method" => "reportWalrusUploadResult", "result" => "ok").increment(1);
        }
        Err(e) => {
            error!("❌ Failed to report Walrus result: {}", e);
            counter!("rofl_contract_calls_total", "method" => "reportWalrusUploadResult", "result" => "err").increment(1);
            return Err(e.into());
        }
    }
    
    histogram!("rofl_contract_call_duration_seconds", "method" => "reportWalrusUploadResult")
        .record(start_time.elapsed().as_secs_f64());
    
    Ok(())
}

/// Report Sui result using typed contract binding with gas estimation and retry
#[instrument(skip_all, fields(operation_id = %operation_id))]
async fn report_sui_result(
    contract: &AtomicVaultManager<SignerMiddleware<Provider<Http>, LocalWallet>>,
    operation_id: H256,
    result: Result<String>,
) -> Result<()> {
    let start_time = std::time::Instant::now();
    
    let (success, result_string) = match result {
        Ok(tx_hash) => (true, tx_hash),
        Err(e) => (false, format!("Error: {}", e)),
    };
    
    let retry_strategy = ExponentialBackoff::from_millis(1000)
        .max_delay(Duration::from_secs(30))
        .take(3);
    
    let tx_result = Retry::spawn(retry_strategy, || async {
        // Gas estimation with margin - as per official ethers-rs docs
        let call = contract.report_sui_update_result(operation_id, success, result_string.clone());
        let gas_estimate = call.estimate_gas().await?;
        let gas_limit = gas_estimate * 120 / 100; // 20% margin for safety
        
        // Send transaction with estimated gas
        let pending_tx = call.gas(gas_limit).send().await?;
        let receipt = pending_tx.await?;
        
        Ok(receipt.unwrap().transaction_hash)
    }).await;
    
    match tx_result {
        Ok(tx_hash) => {
            info!("📞 Sui result reported: {} (success: {})", tx_hash, success);
            counter!("rofl_contract_calls_total", "method" => "reportSuiUpdateResult", "result" => "ok").increment(1);
        }
        Err(e) => {
            error!("❌ Failed to report Sui result: {}", e);
            counter!("rofl_contract_calls_total", "method" => "reportSuiUpdateResult", "result" => "err").increment(1);
            return Err(e.into());
        }
    }
    
    histogram!("rofl_contract_call_duration_seconds", "method" => "reportSuiUpdateResult")
        .record(start_time.elapsed().as_secs_f64());
    
    Ok(())
}

/// Monitor Sui events with feature flag support
#[instrument(skip_all)]
async fn run_sui_monitor(
    _sui_client: (),
    state: Arc<RoflBridgeState>,
    _semaphore: Arc<Semaphore>,
) -> Result<()> {
    #[cfg(feature = "sui")]
    {
        info!("🔍 Starting Sui event monitor with real client");
        
        let http_client = HttpClient::builder()
            .timeout(Duration::from_secs(30))
            .build()
            .map_err(|e| RoflError::Config(format!("Failed to create HTTP client: {}", e)))?;
        
        let mut interval = interval(Duration::from_secs(30));
        
        loop {
            interval.tick().await;
            
            match get_latest_sui_checkpoint(&http_client, &state.config.sui_rpc_url).await {
                Ok(checkpoint) => {
                    state.save_sui_cursor(checkpoint).await?;
                    debug!("📍 Updated Sui checkpoint: {}", checkpoint);
                }
                Err(e) => {
                    error!("❌ Failed to get Sui checkpoint: {}", e);
                    counter!("rofl_errors_total", "source" => "sui", "type" => "checkpoint").increment(1);
                }
            }
        }
    }
    
    #[cfg(not(feature = "sui"))]
    {
        info!("🔍 Sui monitoring disabled (feature flag not enabled)");
        
        let mut interval = interval(Duration::from_secs(60));
        
        loop {
            interval.tick().await;
            debug!("⏭️ Sui monitoring skipped (feature disabled)");
        }
    }
}

/// Get latest checkpoint from Sui RPC (when sui feature is enabled)
#[cfg(feature = "sui")]
async fn get_latest_sui_checkpoint(
    client: &HttpClient,
    rpc_url: &str,
) -> Result<u64> {
    let payload = serde_json::json!({
        "jsonrpc": "2.0",
        "method": "sui_getLatestCheckpointSequenceNumber",
        "params": [],
        "id": 1
    });
    
    let response = client
        .post(rpc_url)
        .header("Content-Type", "application/json")
        .json(&payload)
        .send()
        .await
        .map_err(RoflError::Http)?;
    
    let status = response.status();
    let response_text = response.text().await.map_err(RoflError::Http)?;
    
            // Manual status checks as per official reqwest docs
        if status.is_success() {
            let json_response: serde_json::Value = serde_json::from_str(&response_text)
                .map_err(|e| RoflError::EventProcessing(format!("Invalid JSON response: {}", e)))?;
            
            // Parse sui_getLatestCheckpointSequenceNumber response - returns string as per official Sui docs
            let checkpoint = json_response
                .get("result")
                .and_then(|v| v.as_str())
                .and_then(|s| s.parse::<u64>().ok())
                .ok_or_else(|| RoflError::EventProcessing("Invalid checkpoint in response".to_string()))?;
            
            Ok(checkpoint)
        } else if status.is_client_error() {
            Err(RoflError::EventProcessing(format!("RPC client error {}: {}", status, response_text)))
        } else if status.is_server_error() {
            Err(RoflError::EventProcessing(format!("RPC server error {}: {}", status, response_text)))
        } else {
            Err(RoflError::EventProcessing(format!("RPC error {}: {}", status, response_text)))
        }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::TempDir;
    
    fn create_test_config() -> (RoflConfig, TempDir) {
        let temp_dir = TempDir::new().unwrap();
        let config = RoflConfig {
            sapphire_rpc_url: "https://testnet.sapphire.oasis.dev".to_string(),
            sapphire_private_key: "0x0000000000000000000000000000000000000000000000000000000000000001".to_string(),
            atomic_vault_manager_address: "0x811182419a4e4F419ec100ac0Cd63fc1Fef2810C".parse().unwrap(),
            sui_rpc_url: "https://fullnode.testnet.sui.io:443".to_string(),
            walrus_base_url: "https://publisher-devnet.walrus.space".to_string(),
            walrus_response_cid_key: "cid".to_string(),
            request_timeout: Duration::from_secs(30),
            max_retries: 3,
            max_concurrent_operations: 10,
            max_block_range: 1000,
            confirmation_blocks: 3,
            storage_path: temp_dir.path().to_string_lossy().to_string(),
            metrics_port: 3001,
        };
        (config, temp_dir)
    }
    
    #[tokio::test]
    async fn test_idempotency_check() {
        let (config, _temp_dir) = create_test_config();
        let db = sled::open(&config.storage_path).unwrap();
        let state = Arc::new(RoflBridgeState::new(db, config));
        
        let event_id = "test-event-123";
        
        // First check should return true (can process)
        assert!(state.check_idempotency(event_id).await.unwrap());
        
        // Create a test event and store it
        let test_event = RoflEvent {
            event_id: event_id.to_string(),
            seq: 1,
            source: "test".to_string(),
            timestamp: Utc::now(),
            block_number: 12345,
            transaction_hash: H256::zero(),
            event_type: RoflEventType::SuiDeviceRegistered,
            payload: RoflEventPayload {
                version: 1,
                raw_data: Vec::new(),
                metadata: HashMap::new(),
            },
            processing_status: EventProcessingStatus::Completed,
            retry_count: 0,
        };
        
        state.store_event(&test_event).await.unwrap();
        
        // Second check should return false (already processed)
        assert!(!state.check_idempotency(event_id).await.unwrap());
    }
    
    #[tokio::test]
    async fn test_ordering_check() {
        let (config, _temp_dir) = create_test_config();
        let db = sled::open(&config.storage_path).unwrap();
        let state = Arc::new(RoflBridgeState::new(db, config));
        
        // First sequence should pass
        assert!(state.check_ordering("test_source", 1).await.unwrap());
        
        // Next sequence should pass
        assert!(state.check_ordering("test_source", 2).await.unwrap());
        
        // Same sequence should fail
        assert!(!state.check_ordering("test_source", 2).await.unwrap());
        
        // Lower sequence should fail
        assert!(!state.check_ordering("test_source", 1).await.unwrap());
        
        // Higher sequence should pass
        assert!(state.check_ordering("test_source", 3).await.unwrap());
    }
    
    #[tokio::test]
    async fn test_cursor_persistence() {
        let (config, _temp_dir) = create_test_config();
        let db = sled::open(&config.storage_path).unwrap();
        let state = Arc::new(RoflBridgeState::new(db.clone(), config.clone()));
        
        // Save cursors
        state.save_sapphire_cursor(12345).await.unwrap();
        state.save_sui_cursor(67890).await.unwrap();
        
        // Create new state instance with same storage
        let state2 = Arc::new(RoflBridgeState::new(db, config));
        state2.load_cursors().await.unwrap();
        
        // Verify cursors were persisted
        assert_eq!(*state2.last_processed_sapphire_block.read().await, 12345);
        assert_eq!(*state2.last_processed_sui_checkpoint.read().await, 67890);
    }
    
    #[test]
    fn test_walrus_json_parsing() {
        let json_response = r#"{"cid": "bafybeihkoviema7g3gxyt6la7vd5ho32ictqbilu3wnlo3rs25m7hr5dmu"}"#;
        let parsed: serde_json::Value = serde_json::from_str(json_response).unwrap();
        let cid = parsed.get("cid").and_then(|v| v.as_str()).unwrap();
        assert_eq!(cid, "bafybeihkoviema7g3gxyt6la7vd5ho32ictqbilu3wnlo3rs25m7hr5dmu");
        
        // Test missing cid field
        let bad_json = r#"{"result": "success"}"#;
        let parsed: serde_json::Value = serde_json::from_str(bad_json).unwrap();
        assert!(parsed.get("cid").and_then(|v| v.as_str()).is_none());
    }
}